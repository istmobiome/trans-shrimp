{
  "hash": "8878bc461ce5065543653aa1dc40d5e9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"3. OTU Workflow\"\ndescription: |\n  Workflows for processing 16S rRNA shrimp and environmental sample data sets using paired end reads, beginning with raw fastq files, ending with sequence and taxonomy tables.\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click here for page build libraries and setup information.\"}\nknitr::opts_chunk$set(echo = TRUE, eval = FALSE)\nset.seed(919191)\nlibrary(dada2); packageVersion(\"dada2\")\nlibrary(ShortRead); packageVersion(\"ShortRead\")\nlibrary(ggplot2); packageVersion(\"ggplot2\")\nlibrary(Biostrings); packageVersion(\"Biostrings\")\npacman::p_load(tidyverse, gridExtra, grid, miaViz,\n               formatR, reactable, gdata, patchwork,\n               kableExtra, microeco, magrittr, \n               rprojroot,\n               tidySummarizedExperiment, scater,\n               install = FALSE, update = FALSE)\n\noptions(scipen = 999)\nknitr::opts_current$get(c(\n  \"cache\",\n  \"cache.path\",\n  \"cache.rebuild\",\n  \"dependson\",\n  \"autodep\"\n))\n#root <- find_root(has_file(\"_quarto.yml\"))\n#source(file.path(root, \"assets\", \"functions.R\"))\n```\n:::\n\n\n\n\n\n::: {.column-margin}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-bordered table-condensed\" style=\"font-size: 14px; width: auto !important; \">\n<caption style=\"font-size: initial !important;\">Code chunk coloring by language</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Color </th>\n   <th style=\"text-align:center;\"> Language </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;color: rgba(245, 245, 245, 255) !important;\"> <span style=\"     border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: rgba(0, 114, 178, 255) !important;margin: -6px; padding: 6px; display: flex;\">blue</span> </td>\n   <td style=\"text-align:center;font-weight: bold;\"> R </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;color: rgba(245, 245, 245, 255) !important;\"> <span style=\"     border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: rgba(213, 94, 0, 255) !important;margin: -6px; padding: 6px; display: flex;\">vermillion</span> </td>\n   <td style=\"text-align:center;font-weight: bold;\"> bash </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;color: rgba(245, 245, 245, 255) !important;\"> <span style=\"     border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: rgba(0, 158, 115, 255) !important;margin: -6px; padding: 6px; display: flex;\">bluish green</span> </td>\n   <td style=\"text-align:center;font-weight: bold;\"> shell </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;color: rgba(245, 245, 245, 255) !important;\"> <span style=\"     border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: rgba(204, 121, 167, 255) !important;margin: -6px; padding: 6px; display: flex;\">reddish purple</span> </td>\n   <td style=\"text-align:center;font-weight: bold;\"> mothur </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nWe make use of many different coding languages in these workflows. Code chucks are colored by language. \n\n\n:::\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Biostrings)\nlibrary(Biostrings)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(readr)\n################################################################################\n########### READ IN THE MAPPING FILE FROM mothur2oligo #########################\n################################################################################\nid_map <- readr::read_delim(\"../pipelineFiles_med/BACTERIA_ONLY/intermediate2\", \n                            delim = \"\\t\", \n                            col_names = FALSE)\nid_map <- id_map %>% dplyr::rename(\"MOTHUR_ID\" = 1) %>% \n                     dplyr::rename(., \"MED_ID\" = 2)\nid_map$MOTHUR_ID_RED <- id_map$MOTHUR_ID\nid_map <- id_map %>%\n          mutate(across(\"MOTHUR_ID_RED\",~ gsub(\"_\\\\d+$\",\"\", .)))\nid_map$MOTHUR_UID <- id_map$MOTHUR_ID\nid_map <- id_map %>%\n          mutate(across(\"MOTHUR_UID\",~ gsub(\".*_\",\"\", .)))\n################################################################################\n########### READ IN THE OTU LIST FROM MOTHUR ###################################\n########### get.otulist(list=final.opti_mcc.list, sort=name) ###################\n################################################################################\notu_list <- readr::read_delim(\"final.opti_mcc.0.03.otu\", \n                              delim = \"\\t\", col_names = FALSE)\notu_list <- otu_list %>% dplyr::rename(\"MOTHUR_ID\" = 1) %>% \n                         dplyr::rename(., \"MOTHUR_OTU\" = 2)\n################################################################################\n########### FUNCTION TO READ IN FASTA FILES  ###################################\n################################################################################\nget_fasta_headers <- function(file_path) {\n    # Read the FASTA file\n    fasta <- readDNAStringSet(file_path)\n    \n    # Extract and return the headers\n    headers <- names(fasta)\n    return(headers)\n}\n################################################################################\nfa_files <- list.files(\"NODES/\", pattern = \".fa\", full.names = FALSE)\nseqmatch <- data.frame()\ntotal_files <- length(fa_files)\ndir.create(file.path(\"ALL_RESULTS\"))  \n################################################################################\nfor (j in seq_along(fa_files)) {\n  tmp_fasta_file <- paste0(\"NODES/\", fa_files[j])\n  #tmp_fasta_file <- paste0(\"NODES/\", j)\n  cat(sprintf(\"Processing file %d of %d: %s\\n\", j, total_files, tmp_fasta_file))\n  tmp_input_ids <- data.frame(get_fasta_headers(tmp_fasta_file))\n  tmp_input_ids <- tmp_input_ids %>% dplyr::rename(\"MED_ID\" = 1)  \n  tmp_input_ids <- tibble::as_tibble(tmp_input_ids)\n  tmp_1 <- dplyr::left_join(tmp_input_ids, id_map, by = \"MED_ID\") \n  tmp_2 <- dplyr::left_join(as.data.frame(tmp_1), \n                            as.data.frame(otu_list), \n                            by = c(\"MOTHUR_ID_RED\" = \"MOTHUR_ID\" ), \n                            keep = FALSE)\n  tmp_summ <- data.frame(table(tmp_2$MOTHUR_OTU, useNA = \"always\"))\n  tmp_summ$file_name <- str_replace(basename(tmp_fasta_file), \".fa\", \"\")\n  tmp_base_name <- str_replace(basename(tmp_fasta_file), \".fa\", \"\")\n  write_delim(tmp_2, \n              paste(\"ALL_RESULTS/\", tmp_base_name, \".txt\", sep = \"\"), \n              delim = \"\\t\")\n  seqmatch <- rbind(seqmatch, tmp_summ) \n  rm(list = ls(pattern = \"tmp_\"))\n}\n\nseqmatch <- seqmatch %>% dplyr::rename(\"MOTHUR_OTU\" = 1) %>% \n                     dplyr::rename(., \"COUNT\" = 2) %>% \n                     dplyr::rename(., \"MED_NODE\" = 3) \nseqmatch$MOTHUR_OTU <- as.character(seqmatch$MOTHUR_OTU)\nseqmatch$MOTHUR_OTU[is.na(seqmatch$MOTHUR_OTU)] <- \"NO_OTU\"\n\nwrite_delim(seqmatch, \"seqmatch.txt\", delim = \"\\t\")\nsaveRDS(seqmatch, \"seqmatch.rds\")\n#save.image(\"seqmatch_workflow.rdata\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nseqmatch <- readRDS(\"files/rdata/seqmatch.rds\")\nseqmatch$MED_NODE <- paste(\"MED\", seqmatch$MED_NODE, sep =\"\")\n#seqmatch$UNIQUE_ID <- paste0(seqmatch$MED_NODE, \"-\", seqmatch$MOTHUR_OTU)\nseqmatch\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary packages\n\ncalculate_summary <- function(data) {\n  max_val <- max(data$COUNT)\n  no_otu_val <- data$COUNT[data$MOTHUR_OTU == \"NO_OTU\"]\n  \n  sum_non_max <- sum(data$COUNT[data$COUNT != max_val])\n  adjusted_sum_non_max <- sum_non_max - ifelse(length(no_otu_val) > 0, no_otu_val, 0)\n  \n  data.frame(\n    max_value = max_val,\n    combined_others = paste(data$MOTHUR_OTU[order(-data$COUNT)], collapse = \", \"),\n    no_otu_value = ifelse(length(no_otu_val) > 0, no_otu_val, NA),\n    sum_non_max_values = sum_non_max,\n    adjusted_sum_non_max = adjusted_sum_non_max\n  )\n}\n\n# Apply the function to each group and combine results\nresult <- seqmatch %>%\n  group_by(MED_NODE) %>%\n  do(calculate_summary(.)) %>%\n  ungroup()\n\nprint(result)\nseqmatch\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nme_ds <- c(\"me_asv_tmp\", \"me_otu_tmp\", \"me_med_tmp\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_tax <- tmp_get$tax_table\n  tmp_samp <- tmp_get$sample_table\n  tmp_st <- tmp_get$otu_table\n  tmp_fasta <- tmp_get$rep_fasta\n\n   for (i in 1:nrow(tmp_tax)){\n       if (tmp_tax[i,2] == \"p__Proteobacteria\" & tmp_tax[i,3] == \"c__Alphaproteobacteria\"){\n           phylum <- base::paste(\"p__Alphaproteobacteria\")\n           tmp_tax[i, 2] <- phylum\n   }   else if (tmp_tax[i,2] == \"p__Proteobacteria\" & tmp_tax[i,3] == \"c__Gammaproteobacteria\"){\n           phylum <- base::paste(\"p__Gammaproteobacteria\")\n           tmp_tax[i, 2] <- phylum\n   }   else if (tmp_tax[i,2] == \"p__Proteobacteria\" & tmp_tax[i,3] == \"c__Epsilonproteobacteria\"){\n           phylum <- base::paste(\"p__Epsilonproteobacteria\")\n           tmp_tax[i, 2] <- phylum\n   }   else if (tmp_tax[i,2] == \"p__Proteobacteria\" & tmp_tax[i,3] == \"c__Zetaproteobacteria\"){\n              phylum <- base::paste(\"p__Zetaproteobacteria\")\n           tmp_tax[i, 2] <- phylum\n   }   else if (tmp_tax[i,2] == \"p__Proteobacteria\" & tmp_tax[i,3] == \"c__\"){\n           phylum <- base::paste(\"p__Proteobacteria\")\n           tmp_tax[i, 2] <- phylum\n       }\n   }\n  tmp_name <- str_replace(j, \"_tmp\", \"_pb\")\n  tmp_me <- microtable$new(sample_table = tmp_samp, \n                         otu_table = tmp_st, \n                         tax_table = tmp_tax)\n                         \n  tmp_me$rep_fasta <- tmp_fasta\n  tmp_me$tidy_dataset()\n  assign(tmp_name, tmp_me)\n  rm(list = ls(pattern = \"tmp_\"))\n}\nrm(class, order, phylum)\nrm(list = ls(pattern = \"_tmp\"))\nobjects()\nrm(i,j)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nme_ds <- c(\"me_asv\", \"me_otu\", \"me_med\", \n           \"me_asv_pb\", \"me_otu_pb\", \"me_med_pb\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  if (str_detect(j, \"_asv\") == TRUE) {\n    tmp_get$add_rownames2taxonomy(use_name = \"ASV\")\n  }\n  else if (str_detect(j, \"_otu\") == TRUE) {\n    tmp_get$add_rownames2taxonomy(use_name = \"OTU\")\n  }\nelse if (str_detect(j, \"_med\") == TRUE) {\n    tmp_get$add_rownames2taxonomy(use_name = \"MED\")\n}\n  rm(list = ls(pattern = \"tmp_\"))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_get$auto_tidy = TRUE\n  tmp_path <- file.path(\"files/rdata/\")\n  saveRDS(tmp_get, paste(tmp_path, j, \".rds\", sep = \"\"))\n  rm(list = ls(pattern = \"tmp_\"))\n}\nme_asv_pb$tax_table\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- c(\"me_asv\", \"me_otu\", \"me_med\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_ds <- microeco::clone(tmp_get)\n  tmp_ds_df <- tmp_ds$otu_table\n\n  tmp_type <- str_replace(rownames(tmp_ds_df)[1], \"\\\\d+\", \"\")\n  tmp_type <- paste(tmp_type, \"_ID\", sep = \"\")\n\n  tmp_ds_df <- tmp_ds_df %>% \n    mutate(total_reads = rowSums(.), \n           .before = 1)\n  tmp_ds_df <- tmp_ds_df  %>% \n    mutate(total_reads_ES = rowSums(select(., contains(\"E_SAMP\"))), \n           .after = \"total_reads\")\n  tmp_ds_df <- dplyr::select(tmp_ds_df, -contains(\"E_SAMP\"))\n  tmp_ds_df <- tmp_ds_df %>% \n    dplyr::mutate(total_reads_SS = rowSums(.[3:ncol(tmp_ds_df)]), \n                  .after = \"total_reads_ES\")\n\n  tmp_ds_df <- tmp_ds_df %>% tibble::rownames_to_column(tmp_type)\n\n  tmp_ds_df[, 5:ncol(tmp_ds_df)] <- list(NULL)\n  tmp_ds_df <- tmp_ds_df %>% \n    dplyr::mutate(perc_reads_in_ES = 100*(\n    total_reads_ES / (total_reads_ES + total_reads_SS)),\n                .after = \"total_reads_SS\")\n  tmp_ds_df$perc_reads_in_ES <- round(tmp_ds_df$perc_reads_in_ES, digits = 6)\n  tmp_name <- purrr::map_chr(j, ~ paste0(., \"_df\"))\n  #tmp_name <- str_replace(j, \"_tmp\", \"_df\")\n  assign(tmp_name, tmp_ds_df)\n  rm(list = ls(pattern = \"tmp_\"))\n}\nobjects(pattern = \"_df\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- c(\"me_asv\", \"me_otu\", \"me_med\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_1 <- data.frame(rowSums(tmp_get$otu_table != 0))\n  tmp_type <- str_replace(rownames(tmp_1)[1], \"\\\\d+\", \"\")\n  tmp_type <- paste(tmp_type, \"_ID\", sep = \"\")\n  tmp_1 <- tmp_1 %>% tibble::rownames_to_column(tmp_type)\n  tmp_1 <- tmp_1 %>% dplyr::rename(\"total_samples\" = 2)  \n\n  tmp_2 <- dplyr::select(tmp_get$otu_table, contains(\"E_SAMP\"))\n  tmp_2$num_samp_ES <- rowSums(tmp_2 != 0)\n  tmp_2 <- dplyr::select(tmp_2, contains(\"num_samp_ES\"))\n  tmp_2 <- tmp_2 %>% tibble::rownames_to_column(tmp_type)\n\n  tmp_3 <- dplyr::select(tmp_get$otu_table, -contains(\"E_SAMP\"))\n  tmp_3$num_samp_SS <- rowSums(tmp_3 != 0)\n  tmp_3 <- dplyr::select(tmp_3, contains(\"num_samp_SS\"))\n  tmp_3 <- tmp_3 %>% tibble::rownames_to_column(tmp_type)\n  #tmp_merge <- get(str_replace(j, \"_tmp\", \"_df\"))\n  tmp_merge <- get(purrr::map_chr(j, ~ paste0(., \"_df\")))\n  tmp_ds_df <- dplyr::left_join(tmp_merge, tmp_1) %>%\n                 dplyr::left_join(., tmp_2) %>%\n                 dplyr::left_join(., tmp_3)\n\n  tmp_ds_df <- tmp_ds_df %>%\n    dplyr::mutate(perc_samp_in_ES = 100*( num_samp_ES / (num_samp_ES + num_samp_SS)),\n                .after = \"num_samp_SS\")\n  tmp_name <- purrr::map_chr(j, ~ paste0(., \"_df\"))\n  #tmp_name <- str_replace(j, \"_tmp\", \"_df\")\n  assign(tmp_name, tmp_ds_df)\n  rm(list = ls(pattern = \"tmp_\"))\n}\nobjects()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- c(\"me_asv_df\", \"me_otu_df\", \"me_med_df\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_ds_df <- tmp_get %>% filter(perc_reads_in_ES > 1 | perc_samp_in_ES > 1)\n  tmp_name_df <- str_replace(j, \"_df\", \"_env\")\n  assign(tmp_name_df, tmp_ds_df)\n  \n  tmp_rem <- tmp_ds_df[,1] %>%  unlist(strsplit(., split = \", \")) \n  tmp_name <- str_replace(j, \"_df\", \"_env_rem\")\n  assign(tmp_name, tmp_rem)\n  rm(list = ls(pattern = \"tmp_\"))\n}\nobjects()\n\nme_ds <- c(\"me_asv\", \"me_otu\", \"me_med\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_es <- microeco::clone(tmp_get)\n  tmp_rem <- get(purrr::map_chr(j, ~ paste0(., \"_env_rem\")))\n  tmp_es$otu_table <- tmp_es$otu_table %>% \n        filter(row.names(tmp_es$otu_table)  tmp_rem)\n  tmp_es$tidy_dataset()\n  tmp_name <- purrr::map_chr(j, ~ paste0(., \"_es\"))\n  assign(tmp_name, tmp_es)\n  rm(list = ls(pattern = \"tmp_\"))\n}\n\nobjects(pattern = \"_es\")\n\ntmp_asv <- me_asv_es$merge_samples(\"TAXON\")\ntmp_asv$otu_table\ntmp_med <- me_med_es$merge_samples(\"TAXON\")\ntmp_med$tax_table\ntmp_otu <- me_otu_es$merge_samples(\"TAXON\")\ntmp_otu$otu_table\nme_asv_env\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- clone(me_med_pb)\n\nt1 <- trans_alpha$new(dataset = me_ds, group = \"TISSUE\")\n# return t1$data_stat\nhead(t1$data_stat)\n\nt1$cal_diff(method = \"KW\")\n# return t1$res_diff\nhead(t1$res_diff)\n\nt1$cal_diff(method = \"KW_dunn\")\n# return t1$res_diff\nhead(t1$res_diff)\n\n# more options\nt1$cal_diff(method = \"KW_dunn\", KW_dunn_letter = FALSE)\nhead(t1$res_diff)\nt1$cal_diff(method = \"wilcox\")\nhead(t1$res_diff)\nt1$cal_diff(method = \"t.test\")\n\n\nt1$cal_diff(method = \"anova\")\n# return t1$res_diff\nhead(t1$res_diff)\n\nt1 <- trans_alpha$new(dataset = me_ds, group = \"TISSUE\")\nt1$cal_diff(method = \"anova\", formula = \"TISSUE+OCEAN\")\nhead(t1$res_diff)\n# see the help document for the usage of formula\n\nt1$cal_diff(method = \"anova\")\n# y_increase can adjust the distance from the letters to the highest point\nt1$plot_alpha(measure = \"Chao1\", y_increase = 0.3)\nt1$plot_alpha(measure = \"Chao1\", y_increase = 0.1)\n# add_sig_text_size: letter size adjustment\nt1$plot_alpha(measure = \"Chao1\", add_sig_text_size = 6, add = \"jitter\", order_x_mean = TRUE)\n\nt1$cal_diff(method = \"wilcox\")\nt1$plot_alpha(measure = \"Chao1\", shape = \"TISSUE\")\n# y_start: starting height for the first label\n# y_increase: increased height for each label\nt1$plot_alpha(measure = \"Chao1\", shape = \"TISSUE\", add = \"jitter\", y_start = 0.1, y_increase = 0.1)\n\nt1$res_diff %<>% base::subset(Significance != \"ns\")\nt1$plot_alpha(measure = \"Chao1\", add = \"dotplot\", xtext_size = 15)\n\nt1 <- trans_alpha$new(dataset = me_ds, group = \"OCEAN\", by_group = \"TISSUE\")\nt1$cal_diff(method = \"wilcox\")\nt1$plot_alpha(measure = \"Shannon\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(t1)\nme_ds$cal_betadiv(unifrac = FALSE)\nunique(me_ds$sample_table$PAIR)\n\n\nt1 <- trans_beta$new(dataset = me_ds, group = \"TISSUE\", measure = \"bray\")\n\nt1$cal_ordination(method = \"PCoA\")\n# t1$res_ordination is the ordination result list\nclass(t1$res_ordination)\n# plot the PCoA result with confidence ellipse\nt1$plot_ordination(plot_color = \"TISSUE\", plot_shape = \"OCEAN\", plot_type = c(\"point\", \"ellipse\"))\n```\n:::\n\n\n\n\n\n\nMERGE SAMPLES ANALYSIS\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- clone(me_med_pb)\nt1 <- trans_abund$new(dataset = me_ds, taxrank = \"Phylum\", ntaxa = 10, groupmean = \"TISSUE\")\ng1 <- t1$plot_bar(others_color = \"grey70\", legend_text_italic = FALSE)\ng1 + theme_classic() + theme(axis.title.y = element_text(size = 18))\n\n# show 40 taxa at Genus level\nt1 <- trans_abund$new(dataset = me_ds, taxrank = \"Phylum\", ntaxa = 40)\ng1 <- t1$plot_heatmap(facet = \"TISSUE\", xtext_keep = FALSE, withmargin = FALSE, plot_breaks = c(0.01, 0.1, 1, 10))\ng1\ng1 + theme(axis.text.y = element_text(face = 'italic'))\n\nt1 <- trans_abund$new(dataset = me_ds, taxrank = \"Phylum\", ntaxa = 6, groupmean = \"TISSUE\")\n# all pie chart in one row\nt1$plot_pie(facet_nrow = 3)\nt1$plot_pie(facet_nrow = 3, add_label = TRUE)\n\nt1 <- trans_abund$new(dataset = me_ds, taxrank = \"Phylum\", ntaxa = 8, groupmean = \"TISSUE\")\nt1$plot_donut(label = FALSE, facet_nrow = 3)\nt1$plot_donut(label = TRUE, facet_nrow = 3)\n\nt1 <- trans_abund$new(dataset = me_ds, taxrank = \"Phylum\", ntaxa = 10, groupmean = \"SPECIES\")\ng1 <- t1$plot_bar(coord_flip = TRUE)\ng1 <- g1 + theme_classic() + theme(axis.title.x = element_text(size = 16), axis.ticks.y = element_blank(), axis.line.y = element_blank())\ng1\ng1 <- t1$plot_bar(clustering_plot = TRUE)\n# In this case, g1 (aplot object) is the combination of different ggplot objects\n# to adjust the main plot, please select g1[[1]]\ng1[[1]] <- g1[[1]] + theme_classic() + theme(axis.title.x = element_text(size = 16), axis.ticks.y = element_blank(), axis.line.y = element_blank())\ng1\n\n\ntmp <- me_ds$merge_samples(\"TISSUE\")\nt1 <- trans_venn$new(dataset = tmp)\n# only show some sets with large intersection numbers\nt1$data_summary %<>% .[.[, 1] > 20, ]\ng1 <- t1$plot_bar(left_plot = TRUE, bottom_height = 0.5, left_width = 0.15, up_bar_fill = \"grey50\", left_bar_fill = \"grey50\", bottom_point_color = \"black\")\ng1\n# g1 is aplot class and can be saved with ggplot2::ggsave, aplot::ggsave or cowplot::save_plot function\n# as g1 is comprised of several sub-plots, please adjust the details for each sub-plot\ng1[[1]]\ng1[[2]]\n\ndataset1 <- me_ds$merge_samples(\"TISSUE\")\nt1 <- trans_venn$new(dataset1)\n# transform venn results to the sample-species table, here do not consider abundance, only use presence/absence.\nt2 <- t1$trans_comm(use_frequency = TRUE)\n# t2 is a new microtable class, each part is considered a sample\nclass(t2)\n# calculate taxa abundance, that is, the frequency\nt2$cal_abund()\nt2$taxa_abund\n# transform and plot\nt3 <- trans_abund$new(dataset = t2, taxrank = \"Phylum\", ntaxa = 8)\nunique(t3$data_abund$Sample)\nt3$plot_bar(bar_full = FALSE, legend_text_italic = T, xtext_angle = 30, color_values = RColorBrewer::brewer.pal(8, \"Set2\"),\n    order_x = c(\"IW\", \"CW\", \"TW\", \"IW&CW\", \"IW&TW\", \"CW&TW\", \"IW&CW&TW\")) + ylab(\"Frequency (%)\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(t3$data_abund$Sample)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nme_ds <- c(\"me_med\", \"me_asv\", \"me_otu\")\nfor (j in me_ds) {\n  tmp_get <- get(j)\n  tmp_get_tab <- data.frame(tmp_get$otu_table)\n  tmp_get_tab <- tmp_get_tab %>% tibble::rownames_to_column(\"ID\")\n  tmp_get_tab <- jamba::mixedSortDF(tmp_get_tab, decreasing = FALSE, \n                                        useRownames = FALSE, byCols = 1)\n  tmp_get_tab <- tmp_get_tab %>% tibble::remove_rownames() \n  tmp_get_tab <- tmp_get_tab %>% tibble::column_to_rownames(\"ID\")\n  tmp_get_tab <- data.frame(t(tmp_get_tab))\n\n  tmp_get_tab_ord <- data.frame(tmp_get$otu_table)\n  tmp_get_tab_ord <- tmp_get_tab_ord %>% tibble::rownames_to_column(\"ID\")\n  tmp_get_tab_ord <- jamba::mixedSortDF(tmp_get_tab_ord, decreasing = TRUE, \n                                        useRownames = FALSE, byCols = 1)\n  tmp_get_tab_ord <- tmp_get_tab_ord %>% tibble::remove_rownames() \n  tmp_get_tab_ord <- tmp_get_tab_ord %>% tibble::column_to_rownames(\"ID\")\n  tmp_get_tab_ord <- data.frame(t(tmp_get_tab_ord))\n\n  tmp_tab_name <- purrr::map_chr(j, ~ paste0(., \"_perfect\"))\n  assign(tmp_tab_name, tmp_get_tab)\n  \n  tmp_tab_ord_name <- purrr::map_chr(j, ~ paste0(., \"_ord_perfect\"))\n  assign(tmp_tab_ord_name, tmp_get_tab_ord)\n  rm(list = ls(pattern = \"tmp_\"))\n  \n}\nobjects(pattern = \"_perfect\")\ndim(me_med_perfect)\ndim(me_med_ord_perfect)\ndim(me_asv_perfect)\ndim(me_asv_ord_perfect)\ndim(me_otu_perfect)\ndim(me_otu_ord_perfect)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#me_ds <- c(\"me_med\", \"me_asv\", \"me_otu\")\nme_ds <- c(\"me_med\")\n\nlibrary(PERFect)\nper_pval <- 0.05\nfor (j in me_ds) {\n  tmp_path <- file.path(\"files/rdata/\")\n  tmp_get <- get(purrr::map_chr(j, ~ paste0(., \"_perfect\")))\n  tmp_pval <- per_pval\n  tmp_get_ord <- get(purrr::map_chr(j, ~ paste0(., \"_ord_perfect\")))\n\n  print(\"Running PERFect_sim on default\")\n  tmp_sim <- PERFect_sim(X = tmp_get, alpha = tmp_pval, Order = \"NP\", center = FALSE)\n  print(\"Finished running PERFect_sim on default\")\n  dim(tmp_sim$filtX)\n  tmp_sim_name <- purrr::map_chr(j, ~ paste0(., \"_perfect_sim\"))\n  assign(tmp_sim_name, tmp_sim)\n  saveRDS(tmp_sim, paste(tmp_path, tmp_sim_name, \".rds\", sep = \"\"))\n  \n  print(\"Running PERFect_sim on Ordered\")\n  tmp_sim_ord <- PERFect_sim(X = tmp_get_ord, alpha = tmp_pval, Order = \"NP\", center = FALSE)\n  dim(tmp_sim_ord$filtX)\n  tmp_sim_ord_name <- purrr::map_chr(j, ~ paste0(., \"_ord_perfect_sim\"))\n  print(\"Finished running PERFect_sim on Ordered\")\n  assign(tmp_sim_ord_name, tmp_sim_ord)\n  saveRDS(tmp_sim_ord, paste(tmp_path, tmp_sim_ord_name, \".rds\", sep = \"\"))\n\n  rm(list = ls(pattern = \"tmp_\"))\n  \n}\nobjects(pattern = \"_sim\")\ndim(me_med_ord_perfect_sim$filtX)\ndim(me_med_perfect_sim$filtX)[2]\ndata.frame(me_med_perfect_sim$pvals)\ndata.frame(me_med_ord_perfect_sim$pvals)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Total 16S rRNA ASVs with p-value less than\", ssu_per_pval[1], \"\\n\")\ntmp_df <- ssu_default_pvals\ntmp_df <- data.frame(tmp_df)\npval_asv <- tmp_df %>% dplyr::summarise(count = sum(tmp_df <= ssu_per_pval))\n\nprint(paste(\"default order: ASVs before checking p value was\", \n            ssu_default_num_asvs, \n            \"and after was\", \n            pval_asv$count[1]), \n      quote = FALSE)\n\nprint(\"--------------------------------------\", quote = FALSE)\n\ntmp_df <- ssu_ord_pvals\ntmp_df <- data.frame(tmp_df)\npval_asv_ord <- tmp_df %>% dplyr::summarise(count = sum(tmp_df <= ssu_per_pval))\n\nprint(paste(\"decreasing order: ASVs before checking p value was\", \n            ssu_ord_num_asvs, \"and after was\", \n            pval_asv_ord$count[1]), \n      quote = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp_a %>% \n   filter(if_any(everything(), ~ str_detect(.x, 'OTU_132')))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#prep for https://env-med.shinyapps.io/microbiem/\ntmp_tax <- me_asv$tax_table\n\ntmp_tax <- tmp_tax %>% mutate_all(funs(str_replace_all(., \"[a-z]__\", \"\")))\ntmp_tax <- tmp_tax %>% unite(\"Taxonomy\", 1:6, remove = TRUE, sep = \";\")\ntmp_tax <- tibble::rownames_to_column(tmp_tax, \"OTU_ID\")\ntmp_tax <- data.frame(sapply(tmp_tax, \n                             gsub, \n                             pattern = \";+$\", \n                             replacement = \"\"))\ntmp_tax\n\ntmp_asv <- me_asv$otu_table\ntmp_asv <- tibble::rownames_to_column(tmp_asv, \"OTU_ID\")\n\nasv_miem_feature <- dplyr::left_join(tmp_asv, tmp_tax, by = \"OTU_ID\")\nwrite_delim(asv_miem_feature, \"asv_miem_feature.txt\", delim = \"\\t\")\n\ntmp_samp <- me_asv$sample_table\ntmp_samp <- tibble::rownames_to_column(tmp_samp, \"Sample_ID\")\ntmp_samp$SampleID <- NULL\ntmp_samp$Sample_type <- \"SAMPLE\"\nasv_miem_sample <- tmp_samp %>% dplyr::relocate(Sample_type, .after = \"Sample_ID\")\nwrite_delim(asv_miem_sample, \"asv_miem_sample.txt\", delim = \"\\t\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#prep for https://env-med.shinyapps.io/microbiem/\ntmp_tax <- me_asv$tax_table\n\ntmp_tax <- tmp_tax %>% mutate_all(funs(str_replace_all(., \"[a-z]__\", \"\")))\ntmp_tax <- tmp_tax %>% unite(\"Taxonomy\", 1:6, remove = TRUE, sep = \";\")\ntmp_tax <- tibble::rownames_to_column(tmp_tax, \"OTU_ID\")\ntmp_tax <- data.frame(sapply(tmp_tax, \n                             gsub, \n                             pattern = \";+$\", \n                             replacement = \"\"))\ntmp_tax\n\ntmp_asv <- me_asv$otu_table\ntmp_asv <- tibble::rownames_to_column(tmp_asv, \"OTU_ID\")\n\nasv_miem_feature <- dplyr::left_join(tmp_asv, tmp_tax, by = \"OTU_ID\")\nwrite_delim(asv_miem_feature, \"asv_miem_feature.txt\", delim = \"\\t\")\n\ntmp_samp <- me_asv$sample_table\ntmp_samp <- tibble::rownames_to_column(tmp_samp, \"Sample_ID\")\ntmp_samp$SampleID <- NULL\ntmp_samp$Sample_type <- \"SAMPLE\"\nasv_miem_sample <- tmp_samp %>% dplyr::relocate(Sample_type, .after = \"Sample_ID\")\nwrite_delim(asv_miem_sample, \"asv_miem_sample.txt\", delim = \"\\t\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#prep for https://env-med.shinyapps.io/microbiem/\ntmp_tax <- me_med$tax_table\n\ntmp_tax <- tmp_tax %>% mutate_all(funs(str_replace_all(., \"[a-z]__\", \"\")))\ntmp_tax <- tmp_tax %>% unite(\"Taxonomy\", 1:6, remove = TRUE, sep = \";\")\ntmp_tax <- tibble::rownames_to_column(tmp_tax, \"OTU_ID\")\ntmp_tax <- data.frame(sapply(tmp_tax, \n                             gsub, \n                             pattern = \";+$\", \n                             replacement = \"\"))\ntmp_tax\n\ntmp_asv <- me_med$otu_table\ntmp_asv <- tibble::rownames_to_column(tmp_asv, \"OTU_ID\")\n\nmed_miem_feature <- dplyr::left_join(tmp_asv, tmp_tax, by = \"OTU_ID\")\nwrite_delim(med_miem_feature, \"med_miem_feature.txt\", delim = \"\\t\")\n\ntmp_samp <- me_med$sample_table\ntmp_samp <- tibble::rownames_to_column(tmp_samp, \"Sample_ID\")\ntmp_samp$SampleID <- NULL\ntmp_samp$Sample_type <- tmp_samp$Sample_ID\nmed_miem_sample <- tmp_samp %>% dplyr::relocate(Sample_type, .after = \"Sample_ID\")\nmed_miem_sample <- med_miem_sample %>%\n  mutate(across(\"Sample_type\", str_replace, \"^.*E_SAMP.*\", \"POS1\")) %>%\n  mutate(across(\"Sample_type\", str_replace, \"^.*A_.*\", \"SAMPLE\")) %>%\n  mutate(across(\"Sample_type\", str_replace, \"^.*UNKN.*\", \"SAMPLE\"))\nwrite_delim(med_miem_sample, \"med_miem_sample.txt\", delim = \"\\t\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncitation(\"microeco\")\ncitation(\"mia\")\n```\n:::\n\n\n\n\n\n\n## Rename NA taxonomic ranks\n\nPhyloseq has an odd way of dealing with taxonomic ranks that have no value---in other words, **NA** in the tax table. The first thing we are going to do before moving forward is to change all of the *NA*s to have a value of the next highest classified rank. For example, `ASV26` is not classified at the Genus level but is at Family level (Xanthobacteraceae). So we change the Genus name to *Family_Xanthobacteraceae*. The code for comes from these two posts on the phyloseq GitHub, both by [MSMortensen](https://github.com/MSMortensen): issue [#850](https://github.com/joey711/phyloseq/issues/850#issuecomment-394771087) and issue [#990](https://github.com/joey711/phyloseq/issues/990#issuecomment-424618425).\n\n> One thing this code does is reassign the functions `class` and `order` to taxonomic ranks. This can cause issues if you need these functions.\n\nSo you need to run something like this `rm(class, order, phylum, kingdom)` at the end of the code to remove these as variables. For now, I have not come up with a better solution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nps_moth <- ps_moth_nc\ntax.clean <- data.frame(tax_table(ps_moth))\nfor (i in 1:6){ tax.clean[,i] <- as.character(tax.clean[,i])}\ntax.clean[is.na(tax.clean)] <- \"\"\n\nfor (i in 1:nrow(tax.clean)){\n    if (tax.clean[i,2] == \"\"){\n        kingdom <- base::paste(\"k_\", tax.clean[i,1], sep = \"\")\n        tax.clean[i, 2:6] <- kingdom\n    } else if (tax.clean[i,3] == \"\"){\n        phylum <- base::paste(\"p_\", tax.clean[i,2], sep = \"\")\n        tax.clean[i, 3:6] <- phylum\n    } else if (tax.clean[i,4] == \"\"){\n        class <- base::paste(\"c_\", tax.clean[i,3], sep = \"\")\n        tax.clean[i, 4:6] <- class\n    } else if (tax.clean[i,5] == \"\"){\n        order <- base::paste(\"o_\", tax.clean[i,4], sep = \"\")\n        tax.clean[i, 5:6] <- order\n    } else if (tax.clean[i,6] == \"\"){\n        tax.clean$Genus[i] <- base::paste(\"f\",tax.clean$Family[i], sep = \"_\")\n        }\n}\ntax_table(ps_moth) <- as.matrix(tax.clean)\nrank_names(ps_moth)\nrm(class, order, phylum, kingdom, i)\n```\n:::\n\n\n\n\nStill the same ranks. That's good. What about the new groups? Let's take a peak at some families.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(get_taxa_unique(ps_moth, \"Family\"), 16)\n```\n:::\n\n\n\n\n\n#### Source Code {.appendix}\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\nThe source code for this page can be accessed on GitHub `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 496 512\" style=\"height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\"/></svg>`{=html} by [clicking this \nlink](https://github.com/istmobiome/trans-shrimp/blob/main/docs/ssu-workflows/compare/index.qmd). \n\n\n\n\n#### Data Availability {.appendix}\n\n\nRaw fastq files available on figshare at [10.25573/data.14686665](https://doi.org/10.25573/data.14686665). Trimmed fastq files (primers removed) available through the ENA under project accession number [PRJEB45074 (ERP129199)](https://www.ebi.ac.uk/ena/browser/view/PRJEB45074). Data generated in this workflow can be accessed on figshare at [10.25573/data.14687184](https://doi.org/10.25573/data.14687184).\n\n\n\n#### Last updated on {.appendix}\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-09-29 11:02:25 PDT\"\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}