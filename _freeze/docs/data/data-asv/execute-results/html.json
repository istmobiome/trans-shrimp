{
  "hash": "9e8d608d6c96c5b459a51db2f9261a4c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data & Scripts\"\nlisting: \n  id: asv-listing\n  contents: listings/data-asv.yml\nmetadata-files: \n  - listings/_metadata.yml\n---\n\n\n::: column-body-outset-right\n\n::: {.cell}\n\n:::\n\n\n\n\nQuick access to pipeline processing scripts and raw data. With these scripts and associated data you can run the processing steps for each analysis. \n\nAll sequence data is linked to projects on the [European Nucleotide Archive (ENA)](https://www.ebi.ac.uk/ena/browser/). The scripts and associated files can be downloaded as `.zip` archives by clicking the links. Or if you prefer, you can copy the scripts directly from the code blocks below.  \n\n:::\n\n::: column-page-inset-right\n\n```{=html}\n\n<style type=\"text/css\">\n.nav-tabs {\n  margin-top: 0.5rem;\n  border-bottom: none;\n}\n\n.callout {\n  margin-top: 0;\n}\n\n.nav-tabs .nav-link {\n  text-align: center;\n  margin-right: 15px;\n  margin-top: 10px;\n  width: 147px;\n  font-size: 0.9em;\n  font-weight: 600;\n}\n\n.nav-tabs .nav-link, \n.nav-tabs .nav-link.active, \n.nav-tabs .nav-item.show .nav-link {\n  border: 1px solid  rgb(222, 226, 230);\n  border-radius: 10px;\n  color: rgb(80,146,221);\n}\n.nav-tabs .nav-link:hover {\n   border-color: rgb(80,146,221);\n   border-width: 1px;\n} \n\n.nav-tabs .nav-link.active, \n.nav-tabs .nav-item.show .nav-link {\n  border-color: rgb(80,146,221);\n  border-width: 2px;\n}\n\n.nav-tabs .nav-link i {\n  display: block;\n  font-size: 3rem;\n  color: rgb(80,146,221);\n  margin-bottom: 5px;\n}\n\n.quarto-listing {\n  margin-top: 2em;\n}\n\n.quarto-listing .listing-name,\n.quarto-listing .listing-author {\n  white-space: nowrap;\n}\n\n.quarto-listing .listing-actions-group h3 {\n  margin-top: 0;\n}\n\n \n</style>\n\n<ul id=\"index-chooser\" class=\"nav nav-tabs\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-asv.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA ASV processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-otu.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA OTU processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-med.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA MED processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-mg.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      Metagenomic processing\n    </a>\n  </li>\n</ul>\n\n<script type=\"text/javascript\">\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n  // get file name\n  const filename = window.location.pathname.split(\"/\").slice(-1)[0];\n\n  // latch active\n  const toolLinks = window.document.querySelectorAll(\"#index-chooser a\");\n  for (const tool of toolLinks) {\n    if (filename && filename !== \"index.html\") {\n      if (tool.href.endsWith(filename)) {\n        tool.classList.add(\"active\");\n      } \n    } else {\n      if (tool.href.endsWith(\"listing-filters.html\")) {\n        tool.classList.add(\"active\");\n      }\n    }\n  }\n  \n  // move heading into table\n  document.querySelector(\".listing-actions-group\").prepend(document.querySelector(\"h3.unlisted\"));\n});\n\n</script>\n```\n\n:::\n\n\n\n\n\n<br/>\n\n## ASV Data and Scripts {.unlisted}\n\n::: {#asv-listing .column-body-outset-right}\n:::\n\n\n## ASV Processing \n\n### Individual Runs \n\nProcessing scripts for ASV analysis of individual sequencing runs using [dada2](https://github.com/benjjneb/dada2). In total, 16S rRNA sequencing was performed on 6 sequencing runs. In the first workflow of the pipeline, runs are processed separately for error rates, dereplication, and ASV inference. At the end of each workflow, forward and reverse reads are merged. \n\n::: panel-tabset\n\n## BCS_26\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_26**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_26                    #####\n#####            PLATES ISTHMO S5, S5, S7, S8              #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_26\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE, n = 20000)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE, n = 20000)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_26_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n#filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n#2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n#plotting errors\n#plotErrors(errF, nominalQ=TRUE)\n#plotErrors(errR, nominalQ=TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_26_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_26_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_26_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_26_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_26 <- makeSequenceTable(mergers)\ndim(BCS_26)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_26)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_26, \"BCS_26/BCS_26.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_26/BCS_26_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_26)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_26 <- qplot(length, data = read_length, \n                     geom = \"histogram\", binwidth = 1, \n                     xlab = \"read length\", \n                     ylab = \"total variants\", \n                     xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_26.png\", plot_BCS_26, width = 7, height = 3)\n\nsave.image(\"BCS_26.rdata\")\n\n```\n:::\n\n\n## BCS_28\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_28**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_28                    #####\n#####               PLATES ISTHMO S3, S4                   #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_28\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_28_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n# filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n# 2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_28_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_28_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_28_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_28_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_28 <- makeSequenceTable(mergers)\ndim(BCS_28)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_28)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_28, \"BCS_28/BCS_28.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_28/BCS_28_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_28)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_28 <- qplot(length, data = read_length, \n                     geom = \"histogram\", binwidth = 1, \n                     xlab = \"read length\", \n                     ylab = \"total variants\", \n                     xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_28.png\", plot_BCS_28, width = 7, height = 3)\n\nsave.image(\"BCS_28.rdata\")\n\n```\n:::\n\n\n## BCS_29\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_29**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_29                    #####\n#####          PLATES ISTHMO S13, S14, S15, S16            #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_29\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_29_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n#filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n#2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_29_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_29_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_29_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_29_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_29 <- makeSequenceTable(mergers)\ndim(BCS_29)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_29)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_29, \"BCS_29/BCS_29.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_29/BCS_29_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_29)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_29 <- qplot(length, data = read_length, \n                     geom = \"histogram\", binwidth = 1, \n                     xlab = \"read length\", \n                     ylab = \"total variants\", \n                     xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_29.png\", plot_BCS_29, width = 7, height = 3)\n\nsave.image(\"BCS_29.rdata\")\n\n```\n:::\n\n\n## BCS_30\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_30**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_30                    #####\n#####          PLATES ISTHMO S17, S18, S19, S20            #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_30\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE, n = 20000)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE, n = 20000)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_30_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n#filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n#2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_30_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_30_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_30_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_30_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_30 <- makeSequenceTable(mergers)\ndim(BCS_30)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_30)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_30, \"BCS_30/BCS_30.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_30/BCS_30_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_30)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_30 <- qplot(length, data = read_length, \n                     geom = \"histogram\", binwidth = 1, \n                     xlab = \"read length\", \n                     ylab = \"total variants\", \n                     xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_30.png\", plot_BCS_30, width = 7, height = 3)\n\nsave.image(\"BCS_30.rdata\")\n\n```\n:::\n\n\n## BCS_34\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_34**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_34                    #####\n#####               PLATES ISTHMO S01, S02                 #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_34\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_34_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n#filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n#2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_34_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_34_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_34_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_34_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_34 <- makeSequenceTable(mergers)\ndim(BCS_34)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_34)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_34, \"BCS_34/BCS_34.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_34/BCS_34_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_34)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_34 <- qplot(length, data = read_length, \n                      geom = \"histogram\", binwidth = 1, \n                      xlab = \"read length\", \n                      ylab = \"total variants\", \n                      xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_34.png\", plot_BCS_34, width = 7, height = 3)\n\nsave.image(\"BCS_34.rdata\")\n\n```\n:::\n\n\n## BCS_35\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run **BCS_35**\"}\n################################################################\n#####           TRANSISTHMIAN SHRIMP MICROBIOME            #####\n#####                 MISEQ RUN: BCS_35                    #####\n#####           PLATES ISTHMO S9, S10, S11, S12            #####\n################################################################\n#\n# SCRIPT prepared by Matthieu Leray\n# last modified January 28th 2023\n#\n# READ PROCESSING\n#\n# Modified by Jarrod Scott\n# last modified September 11 2024\n################################################################\n\nlibrary(dada2)\nlibrary(tidyverse)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\n\n##Creating filepaths to data \npath <- \"RAW_DATA/BCS_35\"\nhead(list.files(path)) #eventually to check if the path works\n\n##File preparation\n#extracting Forward (fnFs) and Reverse (fnRs) reads from files\nfnFs <- sort(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\nfnRs <- sort(list.files(path, pattern = \"_R2_001.trimmed.fastq\"))\nsample.names <- sapply(strsplit(fnFs, \"_R1_\"), `[`, 1)\nfnFs <-file.path(path, fnFs)\nfnRs <-file.path(path, fnRs)\n\nx <- length(list.files(path, pattern = \"_R1_001.trimmed.fastq\"))\n\nqprofile_fwd <- plotQualityProfile(fnFs[1:x], aggregate = TRUE)\nqprofile_rev <- plotQualityProfile(fnRs[1:x], aggregate = TRUE)\n\nqprofile <- grid.arrange(qprofile_fwd, qprofile_rev, nrow = 1)\nggsave(\"figures/BCS_35_filt_plot_qscores.png\", qprofile, width = 7, height = 3)\n\n#placing filtered files in a new filtered subdirectory\nfiltFs <- file.path(path, \"filtered\", paste0(sample.names, \"_F_filt.fastq\"))\nfiltRs <- file.path(path, \"filtered\", paste0(sample.names, \"_R_filt.fastq\"))\nnames(filtFs) <- sample.names\nnames(filtRs) <- sample.names\n\n#filtering and trimming, here truncation at 220 (Fwd) and 180 (Rev) bp, \n#2expected errors max (N discarded automatically)\n\nout <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180),\n                        maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,\n                        compress=TRUE, multithread=20)\n\nhead(out)\n\n#learning error rates\nerrF <- learnErrors(filtFs, multithread = TRUE)\nerrR <- learnErrors(filtRs, multithread = TRUE)\n\n## ----plot_errF------------------------------\np3 <- plotErrors(errF, nominalQ = TRUE)\nggsave(\"figures/BCS_35_plot_errorF_1.png\", p3, width = 7, height = 5)\nggsave(\"figures/BCS_35_plot_errorF_2.png\", p3)\n## ----plot_errR------------------------------\np4 <- plotErrors(errR, nominalQ = TRUE)\nggsave(\"figures/BCS_35_plot_errorR_1.png\", p4, width = 7, height = 5)\nggsave(\"figures/BCS_35_plot_errorR_2.png\", p4)\n\n##Dereplicating reads\nsam.names <- sapply(strsplit(basename(filtFs), \"_F_\"), `[`, 1)\nderepFs <- derepFastq(filtFs)\nnames(derepFs) <- sam.names\nderepRs <- derepFastq(filtRs)\nnames(derepRs) <- sam.names\n\n##Infering Sequence Variants\ndadaFs <- dada(derepFs, err = errF, pool = \"pseudo\", multithread = TRUE)\ndadaFs[[1]]\ndadaRs <- dada(derepRs, err = errR, pool = \"pseudo\", multithread = TRUE)\ndadaRs[[1]]\n\n##Merging paired ends\nmergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs)\nBCS_35 <- makeSequenceTable(mergers)\ndim(BCS_35)\n# [1]   384 29481\ntable(nchar(getSequences(BCS_35)))\n\n#exporting files to use in the next part of the workflow\nsaveRDS(BCS_35, \"BCS_35/BCS_35.rds\")\n\n#tracking changes through each step\ngetN <- function(x) sum(getUniques(x))\ntrack <-    cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN),\n                  sapply(mergers, getN))\ncolnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\",\n                        \"merged\")\nrownames(track) <- sam.names\nwrite.table(track, \"BCS_35/BCS_35_read_changes.txt\", sep = \"\\t\", quote = FALSE,\n            col.names=NA)\n\nread_length <-  data.frame(nchar(getSequences(BCS_35)))\n\ncolnames(read_length) <- \"length\"\n\nplot_BCS_35 <- qplot(length, data = read_length, \n                     geom = \"histogram\", binwidth = 1, \n                     xlab = \"read length\", \n                     ylab = \"total variants\", \n                     xlim = c(225,275)) \nggsave(\"figures/read_length_before_pseudo_BCS_35.png\", plot_BCS_35, width = 7, height = 3)\n\nsave.image(\"BCS_35.rdata\")\n\n```\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"false\"}\nconda activate R\nRscript BCS_26.R\nRscript BCS_28.R\nRscript BCS_29.R\nRscript BCS_30.R\nRscript BCS_34.R\nRscript BCS_35.R\n```\n:::\n\n\n### Merged Runs\n\nOnce these workflows finish, we then merge the 6 sequence tables together and proceed with chimera removal and taxonomic classification. \n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Processing script for run merged runs\"}\n#!/usr/bin/env Rscript\nset.seed(919191)\nlibrary(dada2); packageVersion(\"dada2\")\nlibrary(ggplot2)\nlibrary(ff)\nlibrary(phyloseq)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(decontam)\nlibrary(grid)\nlibrary(ShortRead); packageVersion(\"ShortRead\")\nlibrary(Biostrings); packageVersion(\"Biostrings\")\nlibrary(DECIPHER); packageVersion(\"DECIPHER\")\n\n########################################\n#\n# 2. MERGE ALL SEQ TABS\n#\n########################################\n\n############################################\n# PROBLEM: Duplicated sample names \n# detected in the sequence table row names: \n# 7512-G, 7512-H, 7512-M, 7512-S\n# BCS_30 and BCS_35\n# FOR BCS_30 changed name to 7512A...\n# FOR BCS_35 changed name to 7512B...\n############################################\n\nBCS_26 <- readRDS(\"BCS_26/BCS_26.rds\")\nBCS_28 <- readRDS(\"BCS_28/BCS_28.rds\")\nBCS_29 <- readRDS(\"BCS_29/BCS_29.rds\")\nBCS_30 <- readRDS(\"BCS_30/BCS_30.rds\")\nBCS_34 <- readRDS(\"BCS_34/BCS_34.rds\")\nBCS_35 <- readRDS(\"BCS_35/BCS_35.rds\")\n\nseqtab.merge <- mergeSequenceTables(BCS_26, BCS_28, BCS_29, \n                                    BCS_30, BCS_34, BCS_35\n                                    )\ndim(seqtab.merge)\ntable(nchar(getSequences(seqtab.merge)))\n\nread_length_all <-  data.frame(nchar(getSequences(seqtab.merge)))\ncolnames(read_length_all) <- \"length\"\nplot_all <- qplot(length, data = read_length_all, \n                  geom = \"histogram\", binwidth = 1, \n                  xlab = \"read length\", \n                  ylab = \"total variants\", \n                  xlim = c(200,400)) \nggsave(\"figures/read_length_before_collapse.png\", \n        plot_all, width = 7, height = 3)\nsaveRDS(seqtab.merge, \"2.seqtab.merge.rds\")\n\nsave.image(\"rdata/2.merge.seqtabs.rdata\")\n\n########################################\n#\n# collapseNoMismatch\n# TESTED, only minor differences in\n# 13 samples. Takes long time to run\n#\n########################################\n\n# seqtab_to_collapse <- collapseNoMismatch(st_all, minOverlap = 20, orderBy = \"abundance\",\n#   identicalOnly = FALSE, vec = TRUE, band = -1, verbose = TRUE)\n\n# dim(seqtab_to_collapse)\n# table(nchar(getSequences(seqtab_to_collapse)))\n\n# read_length_all_collapse <-  data.frame(nchar(getSequences(seqtab_to_collapse)))\n# colnames(read_length_all_collapse) <- \"length\"\n# plot_all_collapse <- qplot(length, data = read_length_all_collapse, geom = \"histogram\", binwidth = 1, xlab = \"read length\", ylab = \"total variants\", xlim = c(200,400)) \n# ggsave(\"figures/read_length_after_collapse.png\", plot_all_collapse, width = 7, height = 3)\n# saveRDS(seqtab_to_collapse, \"seqtab_after_collapse.rds\")\n\n# save.image(\"rdata/2_merge_seqtabs_collapsed.rdata\")\n\n########################################\n#\n# 3. REMOVING CHIMERAS\n#\n########################################\n\n############################################\n# PROBLEM: Duplicated sample names \n# detected in the sequence table row names: \n# 7512-G, 7512-H, 7512-M, 7512-S\n# BCS_30 and BCS_35\n# FOR BCS_30 changed name to 7512A...\n# FOR BCS_35 changed name to 7512B...\n############################################\n\n## REMVOE OUTLIER READ LENGTHS\nseqtab <- seqtab.merge\n#seqtab.merge <- readRDS(\"seqtab_before_collapse.rds\")\ntable(nchar(getSequences(seqtab)))\n\n################################################################################# \n## \n## 220   221   222   223   224   225   226   227   228   229   230   231   232\n##   125    67    14    36    20    13    10    25     9     6     4    27     2\n##   234   235   236   237   238   239   240   241   242   243   244   245   246\n##     9     8  1373   151    46     6    99   407   298   452    31    14    13\n##   247   248   249   250   251   252   253   254   255   256   257   258   259\n##    26    23    19    49   159  3587 84485  3772   319   123    96    20    10\n##   260   261   262   263   264   265   266   267   268   269   270   271   272\n##     8    16     9     4     2     1     1     1     4     2     9     8     4\n##   273   274   275   276   277   278   279   280   281   282   284   285   286\n##     7     3     2     5     1     7     4     1     1     2     1     4     4\n##   288   289   290   291   292   293   294   295   296   297   298   300   303\n##     1     3     1     2     4     8     7     2     3     2     3     2     3\n##   304   305   307   308   309   310   311   312   313   315   316   317   318\n##     1     5     2     3     2     1     3     1     3     1     4     1     3\n##   319   320   321   322   323   324   325   326   328   329   330   332   333\n##     3     1     2     3     2     1     3     1     3     3     2     1     3\n##   334   335   336   337   338   339   340   341   342   343   344   345   346\n##    13     6     7    18     5    25    16    70    52     8     7     8     4\n##   347   348   349   350   351   352   353   354   355   356   357   358   359\n##    25    17    21    10     2    11     1     1     7     6    31     6    15\n##   360   361   362   363   364   365   366   367   368   369   370   371   372\n##    21   161   188    43   141   108    19     9    26     5     3     3     8\n##   373   374   376   377   378   379   380   384   385   386   387   388\n##    11     2     3     5     2     3     1     1     1     1     2     1\n##\n#################################################################################\n\n#######################################################\n## ----REMOVE OUTLIER READ LENGTHS------------------ ##\n#######################################################\n\nseqtab.trim <- seqtab[,nchar(colnames(seqtab)) %in% seq(252, 254)]\ndim(seqtab.trim)\ntable(nchar(getSequences(seqtab.trim)))\n\n#####################\n##   252   253   254\n##  3587 84485  3772\n#####################\n\n#######################################################\n## ----chimera pooled------------------------------- ##\n#######################################################\n\nseqtab.trim.nochim.pool <- \n          removeBimeraDenovo(seqtab.trim, \n                             method = \"pooled\", \n                             multithread = 20, \n                             verbose = TRUE)\ndim(seqtab.trim.nochim.pool)\nsum(seqtab.trim.nochim.pool)/sum(seqtab.trim)\n\nsaveRDS(seqtab.trim.nochim.pool, \"3.seqtab.trim.nochim.pool.rds\")\n\ntable(nchar(getSequences(seqtab.trim.nochim.pool)))\n\ntable(colSums(seqtab.trim.nochim.pool > 0))\ntable(rowSums(seqtab.trim.nochim.pool > 0))\n\n##########################################################\n## ----chimera consensus------------------------------- ##\n##########################################################\n\nseqtab.trim.nochim.consensus <- \n           removeBimeraDenovo(seqtab.trim, \n                              method = \"consensus\", \n                              multithread = 20, \n                              verbose = TRUE)\ndim(seqtab.trim.nochim.consensus)\nsum(seqtab.trim.nochim.consensus)/sum(seqtab.trim)\n\nsaveRDS(seqtab.trim.nochim.consensus, \"3.seqtab.trim.nochim.consensus.rds\")\n\ntable(nchar(getSequences(seqtab.trim.nochim.consensus)))\n\ntable(colSums(seqtab.trim.nochim.consensus > 0))\ntable(rowSums(seqtab.trim.nochim.consensus > 0))\n\n##########################################################\n## ----tracking changes-------------------------------- ##\n##########################################################\n\ngetN <- function(x) sum(getUniques(x))\ntrack <- cbind(rowSums(seqtab), \n               rowSums(seqtab.trim), \n               rowSums(seqtab.trim.nochim.pool), \n               rowSums(seqtab.trim.nochim.consensus))\n\ncolnames(track) <- c(\"merged\", \"trim\", \"chimera_pool\", \"chimera_concensus\")\nwrite.table(track, \"3.chimera_read_changes_pipeline.txt\", \n            sep = \"\\t\", quote = FALSE, col.names=NA)\n\nsave.image(\"rdata/3.trim.chimera.rdata\")\n\n########################################\n#\n# 4. ASSIGNING TAXONOMY\n#\n########################################\n\n###########################################################\n# reference datasets formatted for DADA2 can be found here: \n# https://benjjneb.github.io/dada2/training.html\n###########################################################\n\n########################################\n#\n# TAXONOMY chimera = pooled\n#\n########################################\n\n# seqtab <- readRDS(\"3.seqtab.trim.nochim.pool.rds\")\n\n########################################\n# TAXONOMY = silva\n########################################\nseqtab.pool <- seqtab.trim.nochim.pool\n\ntax_silva_v138.pool <- \n              assignTaxonomy(seqtab.pool, \n              \"TAXONOMY_FILES/silva_nr99_v138.1_train_set.fa.gz\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_silva_v138.pool, \"4.tax_silva_v138.pool.rds\")\n\ntax_silva_v132.pool <- \n              assignTaxonomy(seqtab.pool, \n              \"TAXONOMY_FILES/silva_nr_v132_train_set.fa.gz\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_silva_v132.pool, \"4.tax_silva_v132.pool.rds\")\n\n########################################\n# TAXONOMY = RDP\n########################################\n\ntax_rdp_v138.pool <- \n             assignTaxonomy(seqtab.pool, \n             \"TAXONOMY_FILES/rdp_train_set_18.fa.gz\", \n             multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_rdp_v138.pool, \"4.tax_rdp_v138.pool.rds\")\n\n########################################\n#\n# TAXONOMY chimera = consensus\n#\n########################################\n\n#remove(list = ls())\n#seqtab <- readRDS(\"3.seqtab.trim.nochim.consensus.rds\")\n#objects()\n\n########################################\n# TAXONOMY = silva\n########################################\nseqtab.consensus <- seqtab.trim.nochim.consensus\n\ntax_silva_v138.consensus <- \n              assignTaxonomy(seqtab.consensus, \n              \"TAXONOMY_FILES/silva_nr99_v138.1_train_set.fa.gz\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_silva_v138.consensus, \"4.tax_silva_v138.consensus.rds\")\n\ntax_silva_v132.consensus <- \n              assignTaxonomy(seqtab.consensus, \n              \"TAXONOMY_FILES/silva_nr_v132_train_set.fa.gz\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_silva_v132.consensus, \"4.tax_silva_v132.consensus.rds\")\n\n########################################\n# TAXONOMY = RDP\n########################################\n\ntax_rdp_v138.consensus <- \n              assignTaxonomy(seqtab.consensus, \n              \"TAXONOMY_FILES/rdp_train_set_18.fa.gz\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_rdp_v138.consensus, \"4.tax_rdp_v138.consensus.rds\")\n\n########################################\n# TAXONOMY = ITGDB\n########################################\n\ntax_itgdb.consensus <- \n              assignTaxonomy(seqtab.consensus, \n              \"TAXONOMY_FILES/itgdb_dada2.fa\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_itgdb.consensus, \"4.tax_itgdb.consensus.rds\")\n\n########################################\n# TAXONOMY = GSRDB\n########################################\n\ntax_gsrdb.consensus <- \n              assignTaxonomy(seqtab.consensus, \n              \"TAXONOMY_FILES/gsrdb_dada2.fa\", \n              multithread = TRUE, verbose = TRUE)\nsaveRDS(tax_gsrdb.consensus, \"4.tax_gsrdb.consensus.rds\")\n\nsave.image(\"rdata/4.dada2.pipeline.rdata\")\n\nsessionInfo()\ndevtools::session_info()\n\nquit()\n\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\nconda activate R\nRscript 2.dada2_pipeline.R\n```\n:::\n\n\nIn the resources listed above, we include a table that summarizes read changes for each sample through the pipeline. \n\n\n\n::: {.column-body-outset-right}\n\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}