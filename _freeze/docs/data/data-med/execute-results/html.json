{
  "hash": "807c7a4803dffdf97722288d96537af9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data & Scripts\"\nlisting: \n  id: med-listing\n  contents: listings/data-med.yml\nmetadata-files: \n  - listings/_metadata.yml\n---\n\n\n::: column-body-outset-right\n\n::: {.cell}\n\n:::\n\n\n\n\nQuick access to pipeline processing scripts and raw data. With these scripts and associated data you can run the processing steps for each analysis. \n\nAll sequence data is linked to projects on the [European Nucleotide Archive (ENA)](https://www.ebi.ac.uk/ena/browser/). The scripts and associated files can be downloaded as `.zip` archives by clicking the links. Or if you prefer, you can copy the scripts directly from the code blocks below.  \n\n:::\n\n::: column-page-inset-right\n\n```{=html}\n\n<style type=\"text/css\">\n.nav-tabs {\n  margin-top: 0.5rem;\n  border-bottom: none;\n}\n\n.callout {\n  margin-top: 0;\n}\n\n.nav-tabs .nav-link {\n  text-align: center;\n  margin-right: 15px;\n  margin-top: 10px;\n  width: 147px;\n  font-size: 0.9em;\n  font-weight: 600;\n}\n\n.nav-tabs .nav-link, \n.nav-tabs .nav-link.active, \n.nav-tabs .nav-item.show .nav-link {\n  border: 1px solid  rgb(222, 226, 230);\n  border-radius: 10px;\n  color: rgb(80,146,221);\n}\n.nav-tabs .nav-link:hover {\n   border-color: rgb(80,146,221);\n   border-width: 1px;\n} \n\n.nav-tabs .nav-link.active, \n.nav-tabs .nav-item.show .nav-link {\n  border-color: rgb(80,146,221);\n  border-width: 2px;\n}\n\n.nav-tabs .nav-link i {\n  display: block;\n  font-size: 3rem;\n  color: rgb(80,146,221);\n  margin-bottom: 5px;\n}\n\n.quarto-listing {\n  margin-top: 2em;\n}\n\n.quarto-listing .listing-name,\n.quarto-listing .listing-author {\n  white-space: nowrap;\n}\n\n.quarto-listing .listing-actions-group h3 {\n  margin-top: 0;\n}\n\n \n</style>\n\n<ul id=\"index-chooser\" class=\"nav nav-tabs\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-asv.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA ASV processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-otu.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA OTU processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-med.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      16S rRNA MED processing\n    </a>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <a class=\"nav-link\" href=\"data-mg.html\">\n      <i class=\"bi bi-database-fill\"></i>\n      Metagenomic processing\n    </a>\n  </li>\n</ul>\n\n<script type=\"text/javascript\">\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n  // get file name\n  const filename = window.location.pathname.split(\"/\").slice(-1)[0];\n\n  // latch active\n  const toolLinks = window.document.querySelectorAll(\"#index-chooser a\");\n  for (const tool of toolLinks) {\n    if (filename && filename !== \"index.html\") {\n      if (tool.href.endsWith(filename)) {\n        tool.classList.add(\"active\");\n      } \n    } else {\n      if (tool.href.endsWith(\"listing-filters.html\")) {\n        tool.classList.add(\"active\");\n      }\n    }\n  }\n  \n  // move heading into table\n  document.querySelector(\".listing-actions-group\").prepend(document.querySelector(\"h3.unlisted\"));\n});\n\n</script>\n```\n\n:::\n\n\n\n\n\n<br/>\n\n## MED Data and Scripts {.unlisted}\n\n::: {#med-listing .column-body-outset-right}\n:::\n\n## MED Processing \n\nProcessing scripts for [Minimum Entropy Decomposition (MED)](https://merenlab.org/2014/11/04/med/) analysis. The pipeline begins with the output fasta and count files from the `align.seqs` part of the mothur OTU pipeline. From there we use mothur to remove negative control samples, check for chimera, and run taxonomic classifications. It is important to note that the MED workflow does not precluster sequences (as in the mothur pipeline) because MED relies on every sequence (including redundant reads) for the analysis. This pipeline has four main steps:\n\n1. run the mothur workflow.   \n2. modify and run the `mothur2oligo.sh` script. This script transforms the mothur output to appropriate format for MED. It must be run in the mothur environment because the script uses mothur. We need access to the following mothur files to run this script. \n    i. **taxonomy file**: `final_med.taxonomy`   \n    ii. **count file**: `final_med.count_table`   \n    iii. **fasta file**: `final_med.fasta`   \n3. trim uninformative columns from alignment (in the MED environment)     \n4. run the MED command\n\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"mothur processing script for MED analysis\"}\nset.dir(output=/pool/genomics/stri_istmobiome/data/TRANS_SHRIMP/16S/MOTHUR/pipelineFiles_med/)\n\nsystem(cp pipelineFiles/PROCESSING_FILES/shrimp.trim.contigs.good.unique.good.filter.unique.fasta pipelineFiles_med/)\nsystem(cp pipelineFiles/PROCESSING_FILES/shrimp.trim.contigs.good.unique.good.filter.count_table pipelineFiles_med/)\n\n############################################################\n### Just copied the fasta and count files from last command\n############################################################\n\n############################################################\n### ############  FOR MED REMOVED PRECLUST #################\n############################################################\n\n############################################################\n### ############  REMOVE NEGATIVE CONTROL ##################\n### from https://forum.mothur.org/t/negative-control/2754/16\n############################################################\n\nget.groups(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.fasta, count=shrimp.trim.contigs.good.unique.good.filter.count_table, groups=Control_49-Control_23-Control_17-Control_24-Control_14-Control_44-Control_20-Control_33-Control_41-Control_29-Control_50-Control_22-Control_19-Control_18-Control_48-Control_13-Control_21-Control_16-Control_30-Control_5-Control_42-Control_25-Control_51-Control_40-Control_15-Control_36-Control_47-Control_27-Control_32-Control_8-Control_3-Control_4-Control_6-Control_45-Control_26-Control_46-Control_53-Control_7-Control_12-Control_10-Control_9-Control_35-Control_54-Control_2-Control_43-Control_1-Control_11-Control_52-Control_38-Control_34-Control_56-Control_37-Control_28-Control_57-Control_31-Control_39-Control_59-Control_55-Control_60-Control_58)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.unique.pick.fasta, new=neg_control.fasta)\nrename.file(input=shrimp.trim.contigs.good.unique.good.filter.pick.count_table, new=neg_control.count_table)\nsummary.seqs(fasta=neg_control.fasta, count=neg_control.count_table, processors=30)\nlist.seqs(count=neg_control.count_table)\n\n########################################################################################################\n### modified neg_control.count_table: \n### 1. remove first two rows\n### 2. in BBEdit run \\t\\d+,.*\n### 3. in R\n###     library(tidyverse)\n###     a <- read_tsv(\"neg_control.count_table\")\n###     b <- read_tsv(\"shrimp.trim.contigs.good.unique.good.filter.count_table\")\n###     e <- dplyr::left_join(a, b, by = \"Representative_Sequence\")\n###     write.table(e, \"results.txt\", row.names = FALSE, quote = FALSE, sep = \"\\t\")\n### 4. Replace accnos file with new list. Removed sequences that were found less than 10% in Neg control\n########################################################################################################\n    \nremove.seqs(accnos=neg_control_subset.accnos, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.fasta, count=shrimp.trim.contigs.good.unique.good.filter.count_table)\ncount.groups(count=current)\n########################################################\n## ADDED this command to remove NC samples\n#\n\n## [ERROR]: Control_18 is not in your count table. Please correct.\n## [ERROR]: Control_5 is not in your count table. Please correct.\n\nremove.groups(count=shrimp.trim.contigs.good.unique.good.filter.pick.count_table, fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.fasta, groups=Control_1-Control_10-Control_11-Control_12-Control_13-Control_14-Control_15-Control_16-Control_17-Control_19-Control_2-Control_20-Control_21-Control_22-Control_23-Control_24-Control_25-Control_26-Control_27-Control_28-Control_29-Control_3-Control_30-Control_31-Control_32-Control_33-Control_34-Control_35-Control_36-Control_37-Control_38-Control_39-Control_4-Control_40-Control_41-Control_42-Control_43-Control_44-Control_45-Control_46-Control_47-Control_48-Control_49-Control_50-Control_51-Control_52-Control_53-Control_54-Control_55-Control_56-Control_57-Control_58-Control_59-Control_6-Control_60-Control_7-Control_8-Control_9)\n########################################################\n\nsummary.seqs(fasta=current, count=current, processors=30)\ncount.groups(count=current)\n\n########################################\n### NEGATIVE CONTROLS Should be GONE ###\n########################################\n\nchimera.vsearch(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.count_table, dereplicate=t, processors=30)\nsummary.seqs(fasta=current, count=current, processors=30)\ncount.groups(count=current)\n\nclassify.seqs(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table, reference=reference_dbs/gsrdb.fasta, taxonomy=reference_dbs/gsrdb.tax, processors=30)\nremove.lineage(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.count_table, taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.gsrdb.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)\n\nsummary.seqs(fasta=current, count=current, processors=30)\nsummary.tax(taxonomy=current, count=current, processors=30)\ncount.groups(count=current)\n\n##########################\nrename.file(fasta=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.pick.fasta, count=shrimp.trim.contigs.good.unique.good.filter.pick.pick.denovo.vsearch.pick.count_table, taxonomy=shrimp.trim.contigs.good.unique.good.filter.unique.pick.pick.denovo.vsearch.gsrdb.wang.pick.taxonomy, prefix=final_med)\n\n```\n:::\n\n\n\nOnce you have the script and data you simply run the pipeline like so. \n\n\n\n::: {.cell}\n\n```{.zsh .cell-code}\nmothur med_batchfile_processing\n```\n:::\n\n\n\nOnce the mothur portion of the workflow is complete, the script [`mothur2oligo.sh`](https://github.com/DenefLab/MicrobeMiseq/tree/master/mothur2oligo) needs to be run in the `mothur` environment and modified for your specific purposes. You should not need to modify the associated `renamer.pl` script but it does need to be in the same location as `mothur2oligo.sh`. \n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nbash mothur2oligo.sh\n```\n:::\n\n\n\n::: panel-tabset\n\n## mothur2oligo\n\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"Expand for the `mothur2oligo.sh` script\"}\nconda activate mothur\n# USAGE: sh mothur2oligo.sh\n# This is a shell script for transforming mothur output to appropriate format for \n# A. murat Eren's oligotyping pipeline \n\n## Set variables\n\n# Adjust the file names to your own study - these are the files from the mothur SOP\ntaxonomy=\"pipelineFiles_med/final_med.taxonomy\"\nfasta=\"pipelineFiles_med/final_med.fasta\"\ncount=\"pipelineFiles_med/final_med.count_table\"\nprocessors=28\n\n# Set the taxon you want to select, separate taxonomic levels with \";\" \n# Do not touch inner and outer quotes\ntaxon=\"'Bacteria;-Archaea;'\"\n\n\n################################\n########## Script  #############\n################################\n\nredundantFasta=$(echo ${fasta}.pick.redundant.fasta | sed 's/.fasta//')\ngroups=$(echo ${count}.pick.redundant.groups | sed 's/.count_table//') \n\n# Call mothur commands for generating deuniqued fasta file for a specific lineage\nmothur \"#set.current(processors=$processors); get.lineage(taxonomy=$taxonomy, taxon=$taxon, count=$count); list.seqs(count=current); get.seqs(accnos=current, fasta=$fasta); deunique.seqs(fasta=current, count=current)\"\n\n# Replace all \"_\" in fasta header with a \":\"\ncat $groups | sed 's/_/:/g' > intermediate1\n# Make a file which maps sample names to sequence headers\npaste $groups intermediate1 | awk 'BEGIN{FS=\"\\t\"}{print $1\"\\t\"$2\"_\"$3}' > intermediate2\n\n# Perl script to rename the headers of the fasta to include the sample name at the beginning followed by a \"_\"\nperl renamer.pl $redundantFasta intermediate2 \n\n```\n:::\n\n\n\n## renamer\n\n\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"and the companion `renamer.pl` script\"}\nconda activate mothur\n#! /usr/bin/perl\n#from http://www.perlmonks.org/?node_id=975419\n\nuse strict;\nuse warnings;\n\n@ARGV == 2 or die \"usage: $0 <multifasta file> <header replacement fil\n+e>\\n\";\n\nmy ( $fasta_file, $header_file ) = @ARGV;\nmy $destination = $fasta_file . '_headers-replaced.fasta';\n\nopen IN2, '<', $header_file or die \"Can't read from tab-delimited head\n+er replacement file $header_file: $!\\n\";\n\nmy %head_seqs;\nwhile ( <IN2> ) {\n    chomp;\n    my ( $old, $new ) = split /\\t/;\n    $head_seqs{ $old } = $new;\n    }\nclose IN2;\n\nopen IN1, '<', $fasta_file or die \"Can't read from multifasta file wit\n+h alternating lines of headers and sequences $fasta_file: $!\\n\";\n\nopen OUT, '>', $destination or die \"Can't write to file $destination: \n+$!\\n\";    \n\nwhile ( <IN1> ) {\n    if ( /^>(.+)$/ && exists $head_seqs{ $1 } ) {\n        $_ = \">$head_seqs{ $1 }\\n\";\n        }\n    print OUT $_;\n    }\nclose IN1;\nclose OUT;\n\n```\n:::\n\n\n:::\n\nGreat. Now within the oligotype/MED environment run the following commands for the MED analysis. You will need the `mapping.txt` file  linked above for this step. \n\n\n\n::: {.cell}\n\n```{.zsh .cell-code}\nconda activate oligotyping\no-trim-uninformative-columns-from-alignment \\\n        final_med.pick.redundant.fasta_headers-replaced.fasta\n\ndecompose final_med.pick.redundant.fasta_headers-replaced.fasta-TRIMMED \\\n        -E mapping.txt \\\n        --output-directory MED \\\n        --number-of-threads 24 \\\n        --skip-gen-figures\n```\n:::\n\n\n\nIn the resources listed above, we include a table that summarizes read changes for each sample through the pipeline.\n\n\n\n::: {.column-body-outset-right}\n\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}